{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shirishagugulothu/GEN_AI_ASSIGNMENT_2/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsKaiJlPK4mc",
        "outputId": "1c69d317-f9b1-4f87-e39a-a5925b6ac520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your huggingface token...Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "ðŸ·ï¸ Question Answering Demo\n",
            "\n",
            "Enter your question (or 'quit' to exit): what is the power house of the cell?\n",
            "âž¡ï¸ Answer: Mitochondria\n",
            "\n",
            "Enter your question (or 'quit' to exit): Mitochondria is made up of?\n",
            "âž¡ï¸ Answer: small membrane-bound organelles\n",
            "\n",
            "Enter your question (or 'quit' to exit): what is the main role of mitochondria in cell?\n",
            "âž¡ï¸ Answer: power plants\n",
            "\n",
            "Enter your question (or 'quit' to exit): what mitochondria produces?\n",
            "âž¡ï¸ Answer: ATP\n",
            "\n",
            "Enter your question (or 'quit' to exit): The process of producing ATP is known as?\n",
            "âž¡ï¸ Answer: citric acid cycle and oxidative phosphorylation\n",
            "\n",
            "Enter your question (or 'quit' to exit): \n"
          ]
        }
      ],
      "source": [
        "import requests                         # â† Standard HTTPâ€‘client library for sending web requests\n",
        "from getpass import getpass\n",
        "\n",
        "# 1. Replace this with your actual Huggingâ€¯Face API token\n",
        "API_TOKEN = getpass(\"Enter your huggingface token...\")        # â† Personal access token that authenticates you to Huggingâ€¯Face\n",
        "API_URL = \"https://api-inference.huggingface.co/models/deepset/roberta-base-squad2\"\n",
        "                                         # â† Endpoint for the RoBERTaâ€‘baseâ€‘SQuAD2 questionâ€‘answering model\n",
        "\n",
        "headers = {                             # â† Dictionary of HTTP headers sent with every request\n",
        "    \"Authorization\": f\"Bearer {API_TOKEN}\"  #   Adds your token inside a Bearerâ€‘auth header\n",
        "}\n",
        "\n",
        "def answer_question(question: str, context: str) -> str:   # â† Reusable helper that asks the model\n",
        "    \"\"\"\n",
        "    Sends a question plus its context passage to the Huggingâ€¯Face\n",
        "    InferenceÂ API and returns the modelâ€™s answer (or an error message).\n",
        "    \"\"\"\n",
        "    payload = {                         # â† JSON body the model expects\n",
        "        \"inputs\": {\n",
        "            \"question\": question,       #     Userâ€™s question\n",
        "            \"context\": context          #     Background passage the model will search\n",
        "        }\n",
        "    }\n",
        "\n",
        "    try:                                # â† Begin errorâ€‘handling block\n",
        "        response = requests.post(API_URL, headers=headers, json=payload)  # â† Send POST request\n",
        "        response.raise_for_status()     # â† Throw if status â‰¥400 so we catch it below\n",
        "\n",
        "        data = response.json()          # â† Parse JSON response into a Python dict\n",
        "        return data.get(\"answer\", \"[No answer returned]\")  # â† Safely fetch the answer field\n",
        "\n",
        "    except requests.exceptions.RequestException as e:  # â† Any network / HTTP problem\n",
        "        return f\"[Network/API error] {e}\"\n",
        "    except ValueError:                 # â† Malformed JSON (can't decode)\n",
        "        return \"[Error] Unable to decode response\"\n",
        "    except KeyError:                   # â† Unexpected JSON shape (missing 'answer')\n",
        "        return \"[Error] Unexpected response structure\"\n",
        "\n",
        "if __name__ == \"__main__\":             # â† Only run the demo when script is executed directly\n",
        "    # 2. Simple testing interface\n",
        "    context = (                        # â† Example passage the model will read\n",
        "        \"\"\"Mitochondria are small membrane-bound organelles inside most eukaryotic cells\n",
        "           that act as the cellâ€™s â€œpower plantsâ€, producing most of its energy-rich molecule\n",
        "           ATP through processes like the citric acid cycle and oxidative phosphorylation \"\"\"\n",
        "    )\n",
        "\n",
        "    print(\"Question Answering Demo\")  # â† CLI banner\n",
        "    while True:                         # â† REPL loop so you can ask repeatedly\n",
        "        q = input(\"\\nEnter your question (or 'quit' to exit): \").strip()  # â† Prompt user\n",
        "        if not q or q.lower() == \"quit\":  # â† Exit on empty line or â€œquitâ€\n",
        "            break\n",
        "\n",
        "        answer = answer_question(q, context)  # â† Call helper above\n",
        "        print(\"âž¡ï¸Answer:\", answer)            # â† Display modelâ€™s reply\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import transformers (very large library made by huggingface that manages all the LLM models)\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel # Gpt2Tokenizer-->converts tokens(words) into numbers\n",
        "# GPT2LMHeadModel--> the actual gpt2 model that generates the response\n",
        "\n",
        "import torch # A PyTorch library for handling  and working with tensors\n",
        "import textwrap # A simple tool to wrap text to paragraph\n",
        "\n",
        "# Load the tokenizer and model from pretrained models\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "def generate_story(prompt, temperature=0.7):\n",
        "\n",
        "    try:\n",
        "        # Encode the input prompt\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "        # Generate text with sampling and top-k/top-p filtering\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=200,               # limit total output length\n",
        "            do_sample=True,              # it allows random sampling\n",
        "            temperature=temperature,     # temperature controls randomness\n",
        "            top_k=50,                    # picks from top 50 best tokens\n",
        "            top_p=0.95,                  # nucleus sampling (only chooses from the best smallest group)\n",
        "            repetition_penalty=1.2,      # avoids repeating same words over and over again\n",
        "            pad_token_id=tokenizer.eos_token_id  # to avoid warning\n",
        "        )\n",
        "\n",
        "        # Decode and return the generated text\n",
        "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        return generated_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Text generation failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Test Cases â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #\n",
        "\n",
        "# Define a common prompt\n",
        "test_prompt = \"Once upon a time in a futuristic city,\"\n",
        "\n",
        "# Test with different temperature values\n",
        "temperatures = [0.3, 0.7, 1.0, 1.3]\n",
        "\n",
        "print(\"Generated stories with different temperatures:\\n\")\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\n--- Temperature = {temp} ---\\n\")\n",
        "    story = generate_story(test_prompt, temperature=temp)\n",
        "    print(textwrap.fill(story if story else \"[No output due to error]\"))\n",
        "\n",
        "# Temperature = 0.3 â†’ The model produces very predictable, focused text, sticking closely to the most likely next words.\n",
        "# Temperature = 0.7 â†’ The model a balanced output that mixes coherence with some creativityâ€”often and it is good for general tasks.\n",
        "# Temperature = 1.0 â†’ The text is naturally varied and moderately creative, reflecting the modelâ€™s learned probability distribution.\n",
        "# Temperature = 1.3 â†’ The output becomes highly creative and unpredictable, but may also become less coherent.\n"
      ],
      "metadata": {
        "id": "IqABgYshOJuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cbb60be-e10f-42e9-92ca-1c6371c4b8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated stories with different temperatures:\n",
            "\n",
            "\n",
            "--- Temperature = 0.3 ---\n",
            "\n",
            "Once upon a time in a futuristic city, the world is filled with\n",
            "strange and dangerous creatures. But when you're on your own as an\n",
            "alien race who are trying to survive against these terrifying threats\n",
            "of destruction... The first thing that comes into my mind about this\n",
            "game was how it felt like I had been playing for years before going\n",
            "back home after being so long away from all those games where there\n",
            "were no real options or story choices at play (I mean really? What if\n",
            "they just told me what happened?) So while some things may feel\n",
            "different than others but overall feeling good feels right up until\n",
            "now! It's not exactly something new though because we've seen many\n",
            "other titles do too which makes us wonder why people would want one\n",
            "over another - especially since most players will be familiar with\n",
            "them already :) The main problem here however is having enough\n",
            "experience without any sorta \"experience\" then getting stuck between\n",
            "two levels/levels etc.. You'll have trouble finding anything\n",
            "interesting during gameplay either way ;)\n",
            "\n",
            "--- Temperature = 0.7 ---\n",
            "\n",
            "Once upon a time in a futuristic city, one of the first things to\n",
            "happen is that an accident occurs at night. That's when you have your\n",
            "own version: Pilot turns around and sees people running away from each\n",
            "other with their cars (or even dead bodies) floating on top - as if\n",
            "nothing happened... Suddenly it dawns on them something terrible has\n",
            "occurred within this world! And then they rush out after being told by\n",
            "everyone who can hear us \"Don't worry about anything!\" before suddenly\n",
            "disappearing into space for eternity without any further explanation\n",
            "or reason whatsoever!!! The pilots are transported back through these\n",
            "strange events so quickly there would never be another plane crash due\n",
            "not just to what we saw but also because no-one could see our last\n",
            "message until now!!  Â As such, I thought some kind of miracle had been\n",
            "witnessedâ€¦ But those were really only clues which led me towards\n",
            "deeper revelations regarding how aliens got hereâ€¦.\n",
            "\n",
            "--- Temperature = 1.0 ---\n",
            "\n",
            "Once upon a time in a futuristic city, an assassin with extraordinary\n",
            "abilities attacks his team-mates. For most of them, the enemy is not\n",
            "their job; it's up to others who deal and hold on even if they're dead\n",
            "or dying at that point: If necessary, use your weapon for self defense\n",
            "while defending yourself from gunfire instead (as opposed Punishment\n",
            "'We were going insane all night tonight.' \" It was so cold inside our\n",
            "bodies â€” as soon we stepped foot into any doorway there would have\n",
            "been sparks flying everywhere like fireworks when you started firing\n",
            "shots until everyone could sit back down quietly ... I don't know what\n",
            "kind - but he didn`t feel 'right', does this guy just need some love?\n",
            "Does anybody really want him murdered because someone told her about\n",
            "murdering those men?' Even though no one wanted us killed -- maybe\n",
            "only once every week since 1996 , after which nobody will care anymore\n",
            "unless police do something wrong.... Pause! Then look again where\n",
            "things are\n",
            "\n",
            "--- Temperature = 1.3 ---\n",
            "\n",
            "Once upon a time in a futuristic city, there was this giant figure\n",
            "coming forth with its dark eyes. \"Who woulda thought so late at\n",
            "nightâ€¦\"   Hiro and his fellow adventurers saw the old man as they\n",
            "approached out of boredom by an alleyway from below but he waved them\n",
            "off immediately like it might just come to himâ€¦ His voice drifted over\n",
            "what seemed for some unknown reason closer to death before ending\n",
            "abruptly when I entered into two rooms that were similar or even\n",
            "indistinguishable according one element (like my own level). There we\n",
            "came through where you normally wouldn't enter because every room had\n",
            "certain doors open between each door without requiring exit only using\n",
            "their respective names suchas:... A trapdoor made your heart beat less\n",
            "often if looking away(or) while trying too hard not noticing how many\n",
            "more rounds have passed on all walls except maybe those big screen\n",
            "buttons!!! So backtracking about now is pointless?? And why couldnÂ´t i\n",
            "go ahead since everyone started up shortly after? Maybe being\n"
          ]
        }
      ]
    }
  ]
}